# GPT-scratch
Simple implementation of a GPT using a stack of decoder blocks in PyTorch.  

## References
[\[1\]"Attention Is All You Need" paper](https://arxiv.org/abs/1706.03762)
[\[2\]"Transformers From Scratch" by Peter Bloem](https://peterbloem.nl/blog/transformers)
